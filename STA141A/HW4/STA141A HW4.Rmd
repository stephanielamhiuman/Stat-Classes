---
title: "STA141 HW4"
author: "Hiu Man Lam"
date: "11/29/2016"
output: html_document
---
###Problem 1:

```{r}
#package used:
library(stringr) 

setwd("/Volumes/StorEDGE/*ucdavis/STA141A/CarAdvert")

#load the data using readLines()
nums = as.character(1:1531)
files = paste(nums, ".txt", sep = "")
cardata = sapply(files, function(cardata){
  readLines(cardata)
})
```

```{r}
# (.*?) : match everything in a non-greedy way and capture it.
# ?= Positive lookahead
# ?<= Positive lookbehind
# str_extract() extracts the captured text corresponding to the first match, returning a character vector.

######### Year #########
#Match the four digits pattern for year 
year = "(\\d{4})"
year_extract = str_extract(cardata, year)

#correct to the same spelling of Mini-Cooper before extracting them so that the regex pattern below would match
cardata = gsub("Mini Cooper|MINI Cooper","Mini-Cooper",cardata)

######### Make #########
#look behind the year pattern and capture the model's make. 
make = "(?<=\\d{4}\\s)[a-zA-Z]+[a-zA-Z-]*"
make_extract = str_extract(cardata,make)

#The following tries to correct the mispellings by replacing the correct spellings
make_extract = gsub("LINCOLN","Lincoln",make_extract) 
make_extract = gsub("Ram", "RAM", make_extract)
make_extract = gsub("EXCEL", "Excel-Peterson", make_extract)
make_extract = gsub("Hummer","HUMMER",make_extract)
table(make_extract)

######### Model #########
#If it matches the first word followed by a space, discard it and capture the remaining string in that line(model)
model = "(?<=[a-zA-Z]\\s)[a-zA-Z0-9 ]+"
model_extract = str_extract(cardata,model)

######### VIN #########
#look behind the pattern (VIN: ), capture and extract everything in between until we saw the word Stock or Condition in a non-greedy way
vin = "(?<=\\VIN[:]\\s)(.*?)(?=Stock|Condition)"
vin_extract = str_extract(cardata,vin)

######### Price #########
price = "\\$(\\d{1,2})\\,\\d{1,3}" #price is at most five digits with a comma between group of thousand
price_extract = str_extract(cardata, price)

######### Mileage #########
#look behind the pattern (UsedMileage: or Mileage: ),capture and extract the digits after that
mileage = "(?<=UsedMileage|Mileage[:]\\s)(\\d{1,3})\\,\\d{1,3}"
mileage_extract = str_extract(cardata,mileage)

######### Interior color #########
#look behind (Interior: ),capture everything in between without making the pattern(Body or Transmission) part of the match and extract it
interior = "(?<=Interior[:]\\s)(.*?)(?=Body|Transmission|Engine)"
interior_extract = str_extract(cardata,interior)

######### Exterior color #########
#look behind the pattern (Exterior: ),capture everything in between without making the pattern(Interior or Body) part of the match and extract it
exterior = "(?<=Exterior[:]\\s)(.*?)(?=Interior|Body)"
exterior_extract = str_extract(cardata,exterior)

######### Transmission #########
#look behind the pattern (Transmission: ),capture everything in between without making the pattern(Engine) part of the match and extract it
transmission = "(?<=Transmission[:]\\s)(.*?)(?=Engine)"
transmission_extract = str_extract(cardata, transmission)

######### Engine Displacement #########
#look behind the pattern (Engine: ), capture the following digit pattern (X.X) that's end with L and extract it
engine = "(?<=Engine[:]\\s)\\d.\\d(\\L)"
engine_extract = str_extract(cardata, engine)

######### Company name #########
#look behind the pattern (Offered by: ), capture everything in bettween it and the ending pattern( ???)
company = "(?<=Offered by[:]\\s)(.*?)(?=\\s[???])"
company_extract = str_extract(cardata, company)
table(company_extract)

######### Address of the company #########
#look behind the pattern that starts with numbers, followed by a street name that could contain number and letters and a street suffix
address = "(?<=Address[:]\\s)([0-9]+)\\s([0-9a-zA-Z]+)\\s([a-zA-Z])*([0-9]+)*"
address_extract = str_extract(cardata, address)

######### Phone number of the company #########
#Phone has a pattern of (XXX) XXX- XXX
phone = "[(][2-9][0-9]{2}[)] [0-9]{3}-[0-9]{4}"
phone_extract = str_extract(cardata, phone)

######### Website of the company #########
#look behind the pattern (Website: ), capture everything in between it and the ending pattern(Address)
website = "(?<=Website[:]\\s)(.*)(?=Address)"
website_extract = str_extract(cardata, website)
```

```{r}
#create a dataframe
cardf <-data.frame(year_extract, make_extract, model_extract,
                vin_extract, price_extract, mileage_extract,
                interior_extract, exterior_extract, transmission_extract,
                engine_extract, company_extract, address_extract,
                phone_extract, website_extract)

#name the columes
colnames(cardf) <- c("Model(Year)","Model(Make)", "Model", "VIN", "Price",
                  "Mileage", "Interior color", "Exterior color", "Transmission",
                  "Engine displacement(L)", "Name of company",
                  "Street address of the company", "Phone number of the company",
                  "Website of the company")

#convert into csv file
write.csv(cardf, file = "/Volumes/StorEDGE/*ucdavis/STA141A/car.csv")

summary(cardf)
```


###Problem 2
```{r}
#package used:
library(RCurl)
library(xml2)

#Extracting data from webpage
link = read_html("http://anson.ucdavis.edu/~mueller/cveng13.html")

#used xml_find_all to find nodes that matches
doc = xml_find_all(link,"//body//p")
#extract the text
doc = xml_text(doc)

########### Year #############
#since there is no html tag for year, author, and title, I used regex to extract these data
#find the pattern that contains a blanket with 4digits in it, and then extract it
year = "(?<=[(])(\\d{4})(?=[)])"
year_extract = str_extract(doc, year)
year_extract = as.matrix(year_extract) #change character to matrix 

#Use the variable index to get the rows that are NAs
index = which(is.na(year_extract))
year_extract = year_extract[-index,]  #remove the NAs, it would turn the matrix back into character
year_extract = as.matrix(year_extract) #change character back to matrix again 

############# Authors ###########
#Author has a pattern that starts with a captial letter, include it and capture everything after until theres a open blanket
authors = "(.*?)(\\s*+)(.*?)(?=(\\s*)[(])"
authors_extract = str_extract(doc,authors)
authors_extract = as.matrix(authors_extract)
authors_extract = authors_extract[-index,] #remove the NAs

authors_extract = gsub("\n\\s*","",authors_extract) #subsutites the \n with nothing
authors_extract = gsub("  |   |    "," ",authors_extract) #subsutites the space with just one space
authors_extract = gsub("and|&",",",authors_extract)
authors_extract = gsub("HEMO Study Group","HEMO Study Group, .",authors_extract)
authors_extract = gsub("R. Azari","Azari, R.",authors_extract)
authors_extract = as.matrix(authors_extract)  #change character back to matrix again 

############ Title of publication ############
#look behind the pattern ),  or ). , capture everything and space until there is a period or questionmark
title = "((?<=[)][,]\\s)|(?<=[)][.]\\s))((.*?)(\\s)*)+(?=([.]|[?]))"
title_extract = str_extract(doc,title)
title_extract = as.matrix(title_extract)
title_extract = title_extract[-index,] #remove the NAs

title_extract = gsub("\n\\s*","",title_extract)
title_extract = gsub("  |   |    "," ",title_extract)
title_extract = gsub("&e","Ã©",title_extract)
#change from character to matrix
title_extract = as.matrix(title_extract)


#first find a tag that's present for all entries
doc2 = xml_find_all(link, "//body//p")

######### Journal title ##########
#then use xml_find_first to get the subtag of <em> and those that might be missing
journal = xml_find_first(doc2, ".//em")
journal = xml_text(journal)
journal = as.matrix(journal) #change it to matrix
journal = journal[-index,] #remove the NAs

journal = gsub("\\s$","",journal)
journal = gsub("\n\\s*","",journal)
journal = gsub("  |   |    "," ",journal)
journal = gsub("J.American Statistical Association|J. American StatisticalAssociation|J. AmericanStatistical Association","J. American Statistical Association", journal)
journal = gsub("The Annals of Statistics|Annals of Statistics","Annals of Statistics", journal)
table(journal)

journal = as.matrix(journal)
table(journal)
########## Volume ############
#Use xml_find_first to get the subtag of <strong> and those that might be missing
volume = xml_find_first(doc2,".//strong")
volume = xml_text(volume)
volume = as.matrix(volume)
volume = volume[-index,] #remove the NAs
volume = as.matrix(volume) #make sure its in matrix

########## URL ############
#Use xml_find_first to get the subtag of <a href> and those that might be missing
url = xml_find_first(doc2,".//a/@href")
url = xml_text(url)
url = as.matrix(url)
url = url[-index,] #remove the NAs
url = as.matrix(url) #make sure its in matrix
```

```{r}
#create a data frame
df <-data.frame(year_extract, authors_extract, title_extract, journal, volume, url)

#name the columes
colnames(df) <- c("Year of publication", "Authors", "Title of publication", "Journal title", "journal volume", "URL for the publication")

#convert it to csv file
write.csv(df, file = "/Volumes/StorEDGE/*ucdavis/STA141A/journal.csv")

#statistical summary
summary(df)
plot(df$`Year of publication`, main = "histogram of Year of publication", xlab="Year", ylab = "Number of publication")
table(df$`Year of publication`)
table(df$`Journal title`)
table(df$`Authors`)

#count of number of authors by using strplit
atxt.words = lapply(authors_extract,strsplit,split=",")
y = matrix(unlist(atxt.words), ncol = 2, byrow = TRUE)
#paste the last name and first name back together as a pair
coauthor = paste(y[,1],y[,2], sep = ",")

coauthor = gsub(" ","",coauthor)
coauthor = gsub(",",", ",coauthor)
coauthor = as.matrix(coauthor)
summary(coauthor)
```
